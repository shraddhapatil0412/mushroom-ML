{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf0653d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To be more understandable, let's write properties one by one.\\n\\nclasses: edible=e, poisonous=p\\n\\ncap-shape: bell=b, conical=c, convex=x, flat=f, knobbed=k, sunken=s\\n\\ncap-surface: fibrous=f, grooves=g, scaly=y, smooth=s\\n\\ncap-color: brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y\\n\\nbruises: bruises=t, no=f\\n\\nodor: almond=a, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s\\n\\ngill-attachment: attached=a, descending=d, free=f, notched=n\\n\\ngill-spacing: close=c, crowded=w, distant=d\\n\\ngill-size: broad=b, narrow=n\\n\\ngill-color: black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y\\n\\nstalk-shape: enlarging=e, tapering=t\\n\\nstalk-root: bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r, missing=?\\n\\nstalk-surface-above-ring: fibrous=f, scaly=y, silky=k, smooth=s\\n\\nstalk-surface-below-ring: fibrous=f, scaly=y, silky=k, smooth=s\\n\\nstalk-color-above-ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\\n\\nstalk-color-below-ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\\n\\nveil-type: partial=p, universal=u\\n\\nveil-color: brown=n, orange=o, white=w, yellow=y\\n\\nring-number: none=n, one=o,two=t\\n\\nring-type: cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z\\n    \\nspore-print-color: black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y\\n\\npopulation: abundant=a, clustered=c, numerous=n, scattered=s, several=v, solitary=y\\n\\nhabitat: grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To be more understandable, let's write properties one by one.\n",
    "\n",
    "classes: edible=e, poisonous=p\n",
    "\n",
    "cap-shape: bell=b, conical=c, convex=x, flat=f, knobbed=k, sunken=s\n",
    "\n",
    "cap-surface: fibrous=f, grooves=g, scaly=y, smooth=s\n",
    "\n",
    "cap-color: brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y\n",
    "\n",
    "bruises: bruises=t, no=f\n",
    "\n",
    "odor: almond=a, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s\n",
    "\n",
    "gill-attachment: attached=a, descending=d, free=f, notched=n\n",
    "\n",
    "gill-spacing: close=c, crowded=w, distant=d\n",
    "\n",
    "gill-size: broad=b, narrow=n\n",
    "\n",
    "gill-color: black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y\n",
    "\n",
    "stalk-shape: enlarging=e, tapering=t\n",
    "\n",
    "stalk-root: bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r, missing=?\n",
    "\n",
    "stalk-surface-above-ring: fibrous=f, scaly=y, silky=k, smooth=s\n",
    "\n",
    "stalk-surface-below-ring: fibrous=f, scaly=y, silky=k, smooth=s\n",
    "\n",
    "stalk-color-above-ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\n",
    "\n",
    "stalk-color-below-ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\n",
    "\n",
    "veil-type: partial=p, universal=u\n",
    "\n",
    "veil-color: brown=n, orange=o, white=w, yellow=y\n",
    "\n",
    "ring-number: none=n, one=o,two=t\n",
    "\n",
    "ring-type: cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z\n",
    "    \n",
    "spore-print-color: black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y\n",
    "\n",
    "population: abundant=a, clustered=c, numerous=n, scattered=s, several=v, solitary=y\n",
    "\n",
    "habitat: grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc1f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e91084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load dataset\n",
    "df=pd.read_csv(\"mushrooms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8da8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6d00a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>stalk-root</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color stalk-shape stalk-root  \\\n",
       "0            c         n          k           e          e   \n",
       "1            c         b          k           e          c   \n",
       "2            c         b          n           e          c   \n",
       "3            c         n          n           e          e   \n",
       "4            w         b          k           t          e   \n",
       "\n",
       "  stalk-surface-above-ring stalk-surface-below-ring stalk-color-above-ring  \\\n",
       "0                        s                        s                      w   \n",
       "1                        s                        s                      w   \n",
       "2                        s                        s                      w   \n",
       "3                        s                        s                      w   \n",
       "4                        s                        s                      w   \n",
       "\n",
       "  stalk-color-below-ring veil-type veil-color ring-number ring-type  \\\n",
       "0                      w         p          w           o         p   \n",
       "1                      w         p          w           o         p   \n",
       "2                      w         p          w           o         p   \n",
       "3                      w         p          w           o         p   \n",
       "4                      w         p          w           o         e   \n",
       "\n",
       "  spore-print-color population habitat  \n",
       "0                 k          s       u  \n",
       "1                 n          n       g  \n",
       "2                 n          n       m  \n",
       "3                 k          s       u  \n",
       "4                 n          a       g  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to show first five records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a41c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to show how many rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5761a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 8124\n",
      "Number of columns: 23\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows:',df.shape[0])\n",
    "print('Number of columns:',df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28023ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#to show all information about dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a459576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                       0\n",
       "cap-shape                   0\n",
       "cap-surface                 0\n",
       "cap-color                   0\n",
       "bruises                     0\n",
       "odor                        0\n",
       "gill-attachment             0\n",
       "gill-spacing                0\n",
       "gill-size                   0\n",
       "gill-color                  0\n",
       "stalk-shape                 0\n",
       "stalk-root                  0\n",
       "stalk-surface-above-ring    0\n",
       "stalk-surface-below-ring    0\n",
       "stalk-color-above-ring      0\n",
       "stalk-color-below-ring      0\n",
       "veil-type                   0\n",
       "veil-color                  0\n",
       "ring-number                 0\n",
       "ring-type                   0\n",
       "spore-print-color           0\n",
       "population                  0\n",
       "habitat                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f41d12f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the null value\n",
    "sb.heatmap(df.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6477a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>stalk-root</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4208</td>\n",
       "      <td>3656</td>\n",
       "      <td>3244</td>\n",
       "      <td>2284</td>\n",
       "      <td>4748</td>\n",
       "      <td>3528</td>\n",
       "      <td>7914</td>\n",
       "      <td>6812</td>\n",
       "      <td>5612</td>\n",
       "      <td>1728</td>\n",
       "      <td>4608</td>\n",
       "      <td>3776</td>\n",
       "      <td>5176</td>\n",
       "      <td>4936</td>\n",
       "      <td>4464</td>\n",
       "      <td>4384</td>\n",
       "      <td>8124</td>\n",
       "      <td>7924</td>\n",
       "      <td>7488</td>\n",
       "      <td>3968</td>\n",
       "      <td>2388</td>\n",
       "      <td>4040</td>\n",
       "      <td>3148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class cap-shape cap-surface cap-color bruises  odor gill-attachment  \\\n",
       "count   8124      8124        8124      8124    8124  8124            8124   \n",
       "unique     2         6           4        10       2     9               2   \n",
       "top        e         x           y         n       f     n               f   \n",
       "freq    4208      3656        3244      2284    4748  3528            7914   \n",
       "\n",
       "       gill-spacing gill-size gill-color stalk-shape stalk-root  \\\n",
       "count          8124      8124       8124        8124       8124   \n",
       "unique            2         2         12           2          5   \n",
       "top               c         b          b           t          b   \n",
       "freq           6812      5612       1728        4608       3776   \n",
       "\n",
       "       stalk-surface-above-ring stalk-surface-below-ring  \\\n",
       "count                      8124                     8124   \n",
       "unique                        4                        4   \n",
       "top                           s                        s   \n",
       "freq                       5176                     4936   \n",
       "\n",
       "       stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "count                    8124                   8124      8124       8124   \n",
       "unique                      9                      9         1          4   \n",
       "top                         w                      w         p          w   \n",
       "freq                     4464                   4384      8124       7924   \n",
       "\n",
       "       ring-number ring-type spore-print-color population habitat  \n",
       "count         8124      8124              8124       8124    8124  \n",
       "unique           3         5                 9          6       7  \n",
       "top              o         p                 w          v       d  \n",
       "freq          7488      3968              2388       4040    3148  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a5f083e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                       object\n",
       "cap-shape                   object\n",
       "cap-surface                 object\n",
       "cap-color                   object\n",
       "bruises                     object\n",
       "odor                        object\n",
       "gill-attachment             object\n",
       "gill-spacing                object\n",
       "gill-size                   object\n",
       "gill-color                  object\n",
       "stalk-shape                 object\n",
       "stalk-root                  object\n",
       "stalk-surface-above-ring    object\n",
       "stalk-surface-below-ring    object\n",
       "stalk-color-above-ring      object\n",
       "stalk-color-below-ring      object\n",
       "veil-type                   object\n",
       "veil-color                  object\n",
       "ring-number                 object\n",
       "ring-type                   object\n",
       "spore-print-color           object\n",
       "population                  object\n",
       "habitat                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba7255cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply labelencoder for species o/p column, to change \n",
    "#object type data to number type\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#create object of LabelEncoder class\n",
    "le=LabelEncoder()\n",
    "for col in df.columns:\n",
    "    df[col]=le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf5e708e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>stalk-root</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0      1          5            2          4        1     6                1   \n",
       "1      0          5            2          9        1     0                1   \n",
       "2      0          0            2          8        1     3                1   \n",
       "3      1          5            3          8        1     6                1   \n",
       "4      0          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color  stalk-shape  stalk-root  \\\n",
       "0             0          1           4            0           3   \n",
       "1             0          0           4            0           2   \n",
       "2             0          0           5            0           2   \n",
       "3             0          1           5            0           3   \n",
       "4             1          0           4            1           3   \n",
       "\n",
       "   stalk-surface-above-ring  stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "0                         2                         2                       7   \n",
       "1                         2                         2                       7   \n",
       "2                         2                         2                       7   \n",
       "3                         2                         2                       7   \n",
       "4                         2                         2                       7   \n",
       "\n",
       "   stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "0                       7          0           2            1          4   \n",
       "1                       7          0           2            1          4   \n",
       "2                       7          0           2            1          4   \n",
       "3                       7          0           2            1          4   \n",
       "4                       7          0           2            1          0   \n",
       "\n",
       "   spore-print-color  population  habitat  \n",
       "0                  2           3        5  \n",
       "1                  3           2        1  \n",
       "2                  3           2        3  \n",
       "3                  2           3        5  \n",
       "4                  3           0        1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6e33e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    4208\n",
       "1    3916\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aef63961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#how many samples are edible and poisonous\n",
    "#poisonous means 1 and edible means 0\n",
    "#class: discrete means categorical datatype, use countplot()\n",
    "sb.countplot(data=df,x='class')\n",
    "y=df['class'].value_counts()\n",
    "plt.yticks(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af90c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select input and output\n",
    "x=df.drop('class',axis=1)\n",
    "y=df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "461df23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>stalk-root</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0          5            2          4        1     6                1   \n",
       "1          5            2          9        1     0                1   \n",
       "2          0            2          8        1     3                1   \n",
       "3          5            3          8        1     6                1   \n",
       "4          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color  stalk-shape  stalk-root  \\\n",
       "0             0          1           4            0           3   \n",
       "1             0          0           4            0           2   \n",
       "2             0          0           5            0           2   \n",
       "3             0          1           5            0           3   \n",
       "4             1          0           4            1           3   \n",
       "\n",
       "   stalk-surface-above-ring  stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "0                         2                         2                       7   \n",
       "1                         2                         2                       7   \n",
       "2                         2                         2                       7   \n",
       "3                         2                         2                       7   \n",
       "4                         2                         2                       7   \n",
       "\n",
       "   stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "0                       7          0           2            1          4   \n",
       "1                       7          0           2            1          4   \n",
       "2                       7          0           2            1          4   \n",
       "3                       7          0           2            1          4   \n",
       "4                       7          0           2            1          0   \n",
       "\n",
       "   spore-print-color  population  habitat  \n",
       "0                  2           3        5  \n",
       "1                  3           2        1  \n",
       "2                  3           2        3  \n",
       "3                  2           3        5  \n",
       "4                  3           0        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e64f56c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 22)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43ce3e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "827a62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc2ec655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first apply scalling on input data before train the test\n",
    "#Apply standard scaler for input data training and testing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#create object of class StandardScaler\n",
    "ss=StandardScaler()\n",
    "#meas apply standard scaler for x_train data\n",
    "x_train=ss.fit_transform(x_train)   #converts in numpy array\n",
    "x_test=ss.transform(x_test)   #also converts into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56573a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5686, 22), (5686,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44a24644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2438, 22), (2438,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e5e5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function\n",
    "def create_model(model):   #user defined function\n",
    "    #model user defined object which hold the object of algorithm\n",
    "    #first train the model with 70% data\n",
    "    model.fit(x_train,y_train)\n",
    "    #then test the model with 30% data\n",
    "    y_pred=model.predict(x_test)\n",
    "    #generate report\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14b800b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e720ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base line model of classification algo\n",
    "#call inbuilt class LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9add19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of LogisticRegression class\n",
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b55846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1236\n",
      "           1       0.96      0.95      0.95      1202\n",
      "\n",
      "    accuracy                           0.95      2438\n",
      "   macro avg       0.95      0.95      0.95      2438\n",
      "weighted avg       0.95      0.95      0.95      2438\n",
      "\n",
      "[[1189   47]\n",
      " [  66 1136]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "lr=create_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ce2ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give dataset in DecisionTreeClassifier algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1205c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of class DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier(random_state=1)   #bydefault GINI index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c452d9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model with 70% data, use fit() \n",
    "dtc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8273aadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "dtc=create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b9704e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>0.341469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>0.202075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>population</td>\n",
       "      <td>0.179106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>0.122069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>odor</td>\n",
       "      <td>0.038815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bruises</td>\n",
       "      <td>0.030365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>0.027091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>habitat</td>\n",
       "      <td>0.019612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>0.017635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>0.011063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>0.003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>0.003235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>0.002899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>0.001226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input        IG\n",
       "0                 gill-color  0.341469\n",
       "1          spore-print-color  0.202075\n",
       "2                 population  0.179106\n",
       "3                  gill-size  0.122069\n",
       "4                       odor  0.038815\n",
       "5                    bruises  0.030365\n",
       "6                stalk-shape  0.027091\n",
       "7                    habitat  0.019612\n",
       "8     stalk-color-below-ring  0.017635\n",
       "9                 stalk-root  0.011063\n",
       "10                veil-color  0.003339\n",
       "11                 cap-color  0.003235\n",
       "12  stalk-surface-below-ring  0.002899\n",
       "13               ring-number  0.001226\n",
       "14                 ring-type  0.000000\n",
       "15                 cap-shape  0.000000\n",
       "16                 veil-type  0.000000\n",
       "17    stalk-color-above-ring  0.000000\n",
       "18               cap-surface  0.000000\n",
       "19              gill-spacing  0.000000\n",
       "20           gill-attachment  0.000000\n",
       "21  stalk-surface-above-ring  0.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the information gain of each input(each features)\n",
    "#inbuilt method feature_important_ of DecisionTreeClassifier class\n",
    "dict={'input':x.columns,'IG':dtc.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df1=pd.DataFrame(dict)\n",
    "df1.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfc36897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth :  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81      1236\n",
      "           1       0.84      0.71      0.77      1202\n",
      "\n",
      "    accuracy                           0.79      2438\n",
      "   macro avg       0.80      0.79      0.79      2438\n",
      "weighted avg       0.80      0.79      0.79      2438\n",
      "\n",
      "[[1071  165]\n",
      " [ 349  853]]\n",
      "max depth :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      1236\n",
      "           1       0.97      0.85      0.91      1202\n",
      "\n",
      "    accuracy                           0.91      2438\n",
      "   macro avg       0.92      0.91      0.91      2438\n",
      "weighted avg       0.92      0.91      0.91      2438\n",
      "\n",
      "[[1205   31]\n",
      " [ 182 1020]]\n",
      "max depth :  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1236\n",
      "           1       0.96      0.97      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1184   52]\n",
      " [  32 1170]]\n",
      "max depth :  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1236\n",
      "           1       0.97      0.99      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1204   32]\n",
      " [  15 1187]]\n",
      "max depth :  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1236\n",
      "           1       0.98      0.99      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1206   30]\n",
      " [  15 1187]]\n",
      "max depth :  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1236\n",
      "           1       1.00      0.99      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  13 1189]]\n",
      "max depth :  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "max depth :  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "#Pruning Technique : max_depth  : the value of max_depth cannot more than\n",
    "#8  (means <=8) \n",
    "#create object of DecisionTreeClassifier class with gini index and \n",
    "#use parameter max_depth (to remove overfitting)\n",
    "\n",
    "for i in range(1,9): #start=1 stop=9-1=8 step=+1\n",
    "    dtc1=DecisionTreeClassifier(random_state=1,max_depth=i) #bydefault gini\n",
    "    print(\"max depth : \",i)\n",
    "    #call function \n",
    "    dtc1=create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94fffe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "dtc1=DecisionTreeClassifier(random_state=1,max_depth=7) #bydefault gini\n",
    "#call function \n",
    "dtc1=create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46b56c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>0.341469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>0.202075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>population</td>\n",
       "      <td>0.179106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>0.122069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>odor</td>\n",
       "      <td>0.038815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bruises</td>\n",
       "      <td>0.030365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>0.027091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>habitat</td>\n",
       "      <td>0.019612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>0.017635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>0.011063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>0.003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>0.003235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>0.002899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>0.001226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input        IG\n",
       "0                 gill-color  0.341469\n",
       "1          spore-print-color  0.202075\n",
       "2                 population  0.179106\n",
       "3                  gill-size  0.122069\n",
       "4                       odor  0.038815\n",
       "5                    bruises  0.030365\n",
       "6                stalk-shape  0.027091\n",
       "7                    habitat  0.019612\n",
       "8     stalk-color-below-ring  0.017635\n",
       "9                 stalk-root  0.011063\n",
       "10                veil-color  0.003339\n",
       "11                 cap-color  0.003235\n",
       "12  stalk-surface-below-ring  0.002899\n",
       "13               ring-number  0.001226\n",
       "14                 ring-type  0.000000\n",
       "15                 cap-shape  0.000000\n",
       "16                 veil-type  0.000000\n",
       "17    stalk-color-above-ring  0.000000\n",
       "18               cap-surface  0.000000\n",
       "19              gill-spacing  0.000000\n",
       "20           gill-attachment  0.000000\n",
       "21  stalk-surface-above-ring  0.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the information gain of each input(each features)\n",
    "#inbuilt method feature_important_ of DecisionTreeClassifier class\n",
    "dict={'input':x.columns,'IG':dtc1.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df2=pd.DataFrame(dict)\n",
    "df2.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36e98f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min samples leaf:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1236\n",
      "           1       0.96      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1183   53]\n",
      " [  22 1180]]\n",
      "min samples leaf:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1236\n",
      "           1       0.96      0.97      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1184   52]\n",
      " [  42 1160]]\n",
      "min samples leaf:  93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1236\n",
      "           1       0.96      0.97      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1184   52]\n",
      " [  42 1160]]\n",
      "min samples leaf:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1236\n",
      "           1       0.96      0.97      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1184   52]\n",
      " [  42 1160]]\n",
      "min samples leaf:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1236\n",
      "           1       0.96      0.97      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1184   52]\n",
      " [  42 1160]]\n",
      "min samples leaf:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1236\n",
      "           1       0.97      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1196   40]\n",
      " [  67 1135]]\n",
      "min samples leaf:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1236\n",
      "           1       0.97      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1196   40]\n",
      " [  67 1135]]\n",
      "min samples leaf:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1236\n",
      "           1       0.97      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1196   40]\n",
      " [  67 1135]]\n",
      "min samples leaf:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1236\n",
      "           1       0.97      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1196   40]\n",
      " [  67 1135]]\n",
      "min samples leaf:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1236\n",
      "           1       0.97      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1196   40]\n",
      " [  67 1135]]\n"
     ]
    }
   ],
   "source": [
    "#use 2nd purning technique : min_samples_leaf inbuilt parameter of \n",
    "#DecisionTreeClassifier class, it is class used to remove overfitting\n",
    "#leaf meand no child\n",
    "#create object for DesicionTreeClassifier class\n",
    "for i in range(45,101,1):\n",
    "    dtc2=DecisionTreeClassifier(random_state=1,min_samples_leaf=i)\n",
    "    #by default gini index\n",
    "    print(\"min samples leaf: \",i)\n",
    "    #call function\n",
    "    dtc2=create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c8543a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n"
     ]
    }
   ],
   "source": [
    "dtc2=DecisionTreeClassifier(random_state=1,min_samples_leaf=56)\n",
    "dtc2=create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ad436e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>0.359675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>population</td>\n",
       "      <td>0.183977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>0.183061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>0.116462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>0.060130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bruises</td>\n",
       "      <td>0.031966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>0.028519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>odor</td>\n",
       "      <td>0.017145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>habitat</td>\n",
       "      <td>0.016317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>0.000505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input        IG\n",
       "0                 gill-color  0.359675\n",
       "1                 population  0.183977\n",
       "2          spore-print-color  0.183061\n",
       "3                  gill-size  0.116462\n",
       "4                 stalk-root  0.060130\n",
       "5                    bruises  0.031966\n",
       "6                stalk-shape  0.028519\n",
       "7                       odor  0.017145\n",
       "8                    habitat  0.016317\n",
       "9                  ring-type  0.002242\n",
       "10    stalk-color-above-ring  0.000505\n",
       "11                 veil-type  0.000000\n",
       "12               ring-number  0.000000\n",
       "13                veil-color  0.000000\n",
       "14                 cap-shape  0.000000\n",
       "15    stalk-color-below-ring  0.000000\n",
       "16  stalk-surface-below-ring  0.000000\n",
       "17               cap-surface  0.000000\n",
       "18              gill-spacing  0.000000\n",
       "19           gill-attachment  0.000000\n",
       "20                 cap-color  0.000000\n",
       "21  stalk-surface-above-ring  0.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':dtc2.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df2=pd.DataFrame(dict)\n",
    "df2.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed4417f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier with Entropy method\n",
    "#first create object of DecisionTreeClassifier\n",
    "dt_entropy=DecisionTreeClassifier(random_state=1,criterion='entropy')\n",
    "#bydeafult criterion='gini' if not given\n",
    "#formula= -P*log(P)-Q*log(Q )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d7c674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "dt_entropy=create_model(dt_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef13fd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>0.377714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>0.269255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>0.144568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>0.104813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>odor</td>\n",
       "      <td>0.026994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bruises</td>\n",
       "      <td>0.026772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>habitat</td>\n",
       "      <td>0.025989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>population</td>\n",
       "      <td>0.019142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.004753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input        IG\n",
       "0          spore-print-color  0.377714\n",
       "1                 gill-color  0.269255\n",
       "2                  gill-size  0.144568\n",
       "3                 stalk-root  0.104813\n",
       "4                       odor  0.026994\n",
       "5                    bruises  0.026772\n",
       "6                    habitat  0.025989\n",
       "7                 population  0.019142\n",
       "8   stalk-surface-above-ring  0.004753\n",
       "9                stalk-shape  0.000000\n",
       "10              gill-spacing  0.000000\n",
       "11               cap-surface  0.000000\n",
       "12  stalk-surface-below-ring  0.000000\n",
       "13    stalk-color-above-ring  0.000000\n",
       "14    stalk-color-below-ring  0.000000\n",
       "15                 veil-type  0.000000\n",
       "16                veil-color  0.000000\n",
       "17               ring-number  0.000000\n",
       "18                 ring-type  0.000000\n",
       "19           gill-attachment  0.000000\n",
       "20                 cap-color  0.000000\n",
       "21                 cap-shape  0.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the information gain of each input(each features)\n",
    "#inbuilt method feature_important_ of DecisionTreeClassifier class\n",
    "dict={'input':x.columns,'IG':dt_entropy.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df1=pd.DataFrame(dict)\n",
    "df1.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9f3d289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth :  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81      1236\n",
      "           1       0.84      0.71      0.77      1202\n",
      "\n",
      "    accuracy                           0.79      2438\n",
      "   macro avg       0.80      0.79      0.79      2438\n",
      "weighted avg       0.80      0.79      0.79      2438\n",
      "\n",
      "[[1071  165]\n",
      " [ 349  853]]\n",
      "max depth :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      1236\n",
      "           1       0.97      0.85      0.91      1202\n",
      "\n",
      "    accuracy                           0.91      2438\n",
      "   macro avg       0.92      0.91      0.91      2438\n",
      "weighted avg       0.92      0.91      0.91      2438\n",
      "\n",
      "[[1205   31]\n",
      " [ 182 1020]]\n",
      "max depth :  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1236\n",
      "           1       0.96      0.97      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1184   52]\n",
      " [  32 1170]]\n",
      "max depth :  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1236\n",
      "           1       0.97      0.99      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1204   32]\n",
      " [  15 1187]]\n",
      "max depth :  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1236\n",
      "           1       0.98      0.99      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1206   30]\n",
      " [  15 1187]]\n",
      "max depth :  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1236\n",
      "           1       1.00      0.99      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  13 1189]]\n",
      "max depth :  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "max depth :  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9): #start=1 stop=9-1=8 step=+1\n",
    "    dtc3=DecisionTreeClassifier(random_state=1,max_depth=i) #bydefault gini\n",
    "    print(\"max depth : \",i)\n",
    "    #call function \n",
    "    dtc3=create_model(dtc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "499345db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "dtc3=DecisionTreeClassifier(random_state=1,max_depth=7) #bydefault gini\n",
    "#call function \n",
    "dtc3=create_model(dtc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "023904c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>0.341469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>0.202075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>population</td>\n",
       "      <td>0.179106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>0.122069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>odor</td>\n",
       "      <td>0.038815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bruises</td>\n",
       "      <td>0.030365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>0.027091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>habitat</td>\n",
       "      <td>0.019612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>0.017635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>0.011063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>0.003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>0.003235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>0.002899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>0.001226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input        IG\n",
       "0                 gill-color  0.341469\n",
       "1          spore-print-color  0.202075\n",
       "2                 population  0.179106\n",
       "3                  gill-size  0.122069\n",
       "4                       odor  0.038815\n",
       "5                    bruises  0.030365\n",
       "6                stalk-shape  0.027091\n",
       "7                    habitat  0.019612\n",
       "8     stalk-color-below-ring  0.017635\n",
       "9                 stalk-root  0.011063\n",
       "10                veil-color  0.003339\n",
       "11                 cap-color  0.003235\n",
       "12  stalk-surface-below-ring  0.002899\n",
       "13               ring-number  0.001226\n",
       "14                 ring-type  0.000000\n",
       "15                 cap-shape  0.000000\n",
       "16                 veil-type  0.000000\n",
       "17    stalk-color-above-ring  0.000000\n",
       "18               cap-surface  0.000000\n",
       "19              gill-spacing  0.000000\n",
       "20           gill-attachment  0.000000\n",
       "21  stalk-surface-above-ring  0.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the information gain of each input(each features)\n",
    "#inbuilt method feature_important_ of DecisionTreeClassifier class\n",
    "dict={'input':x.columns,'IG':dtc3.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df2=pd.DataFrame(dict)\n",
    "df2.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e719fa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min samples leaf:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1236\n",
      "           1       0.97      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1201   35]\n",
      " [  28 1174]]\n",
      "min samples leaf:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n",
      "min samples leaf:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1236\n",
      "           1       0.96      0.98      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1183   53]\n",
      " [  22 1180]]\n",
      "min samples leaf:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      1236\n",
      "           1       0.95      1.00      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1168   68]\n",
      " [   3 1199]]\n",
      "min samples leaf:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1236\n",
      "           1       0.94      0.98      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1159   77]\n",
      " [  22 1180]]\n",
      "min samples leaf:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1236\n",
      "           1       0.96      0.97      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1184   52]\n",
      " [  42 1160]]\n",
      "min samples leaf:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1236\n",
      "           1       0.96      0.97      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1184   52]\n",
      " [  42 1160]]\n",
      "min samples leaf:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1236\n",
      "           1       0.96      0.97      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1184   52]\n",
      " [  42 1160]]\n",
      "min samples leaf:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1236\n",
      "           1       0.96      0.97      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1184   52]\n",
      " [  42 1160]]\n",
      "min samples leaf:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1236\n",
      "           1       0.97      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1196   40]\n",
      " [  67 1135]]\n",
      "min samples leaf:  97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1236\n",
      "           1       0.97      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1196   40]\n",
      " [  67 1135]]\n",
      "min samples leaf:  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1236\n",
      "           1       0.97      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1196   40]\n",
      " [  67 1135]]\n",
      "min samples leaf:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1236\n",
      "           1       0.97      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1196   40]\n",
      " [  67 1135]]\n",
      "min samples leaf:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1236\n",
      "           1       0.97      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1196   40]\n",
      " [  67 1135]]\n"
     ]
    }
   ],
   "source": [
    "#create object for DesicionTreeClassifier class\n",
    "for i in range(45,101,1):\n",
    "    dtc4=DecisionTreeClassifier(random_state=1,min_samples_leaf=i)\n",
    "    #by default gini index\n",
    "    print(\"min samples leaf: \",i)\n",
    "    #call function\n",
    "    dtc4=create_model(dtc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46cbae74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1236\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1189   47]\n",
      " [   3 1199]]\n"
     ]
    }
   ],
   "source": [
    "dtc4=DecisionTreeClassifier(random_state=1,min_samples_leaf=56)\n",
    "dtc4=create_model(dtc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "536f26fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a7542d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of RandomForestClassifier class\n",
    "rfc=RandomForestClassifier(n_estimators=10,random_state=1)\n",
    "#here n_estimators means take how many no. of decision tree\n",
    "#n_estimators >=10 but n_estimators<=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6332a6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d10d529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Decision Tree:  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision Tree:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,101,1):\n",
    "    rfc=RandomForestClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Decision Tree: \",i)\n",
    "    #call function\n",
    "    rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f436865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "rfc=RandomForestClassifier(n_estimators=10,random_state=1)\n",
    "#by default gini index\n",
    "#call function\n",
    "rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d81ba129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>0.149783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>0.114932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>0.097807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>0.095741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>population</td>\n",
       "      <td>0.091341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.079325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>odor</td>\n",
       "      <td>0.074983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>0.064250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>0.054036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>0.043427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>habitat</td>\n",
       "      <td>0.032413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>0.020341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>0.016073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bruises</td>\n",
       "      <td>0.013877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>0.012891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>0.012471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.010895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>0.010715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>0.002668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>0.001825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input        IG\n",
       "0                 gill-color  0.149783\n",
       "1                  gill-size  0.114932\n",
       "2                  ring-type  0.097807\n",
       "3          spore-print-color  0.095741\n",
       "4                 population  0.091341\n",
       "5   stalk-surface-above-ring  0.079325\n",
       "6                       odor  0.074983\n",
       "7   stalk-surface-below-ring  0.064250\n",
       "8                 stalk-root  0.054036\n",
       "9     stalk-color-above-ring  0.043427\n",
       "10                   habitat  0.032413\n",
       "11              gill-spacing  0.020341\n",
       "12    stalk-color-below-ring  0.016073\n",
       "13                   bruises  0.013877\n",
       "14                 cap-color  0.012891\n",
       "15               stalk-shape  0.012471\n",
       "16               cap-surface  0.010895\n",
       "17               ring-number  0.010715\n",
       "18                 cap-shape  0.002668\n",
       "19                veil-color  0.001825\n",
       "20           gill-attachment  0.000206\n",
       "21                 veil-type  0.000000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':rfc.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df3=pd.DataFrame(dict)\n",
    "df3.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be80651f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth :  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      1236\n",
      "           1       0.89      0.80      0.84      1202\n",
      "\n",
      "    accuracy                           0.85      2438\n",
      "   macro avg       0.86      0.85      0.85      2438\n",
      "weighted avg       0.86      0.85      0.85      2438\n",
      "\n",
      "[[1120  116]\n",
      " [ 243  959]]\n",
      "max depth :  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      1236\n",
      "           1       0.98      0.83      0.90      1202\n",
      "\n",
      "    accuracy                           0.91      2438\n",
      "   macro avg       0.92      0.91      0.91      2438\n",
      "weighted avg       0.92      0.91      0.91      2438\n",
      "\n",
      "[[1220   16]\n",
      " [ 199 1003]]\n",
      "max depth :  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      1236\n",
      "           1       1.00      0.93      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.97      0.96      0.96      2438\n",
      "weighted avg       0.97      0.96      0.96      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  87 1115]]\n",
      "max depth :  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1228    8]\n",
      " [  35 1167]]\n",
      "max depth :  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  20 1182]]\n",
      "max depth :  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  23 1179]]\n",
      "max depth :  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   6 1196]]\n",
      "max depth :  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "#use purning technique \n",
    "#max-depth\n",
    "for i in range(1,9): #start=1 stop=9-1=8 step=+1\n",
    "    rfc1=RandomForestClassifier(n_estimators=10,random_state=1,max_depth=i) #bydefault gini\n",
    "    print(\"max depth : \",i)\n",
    "    #call function \n",
    "    rfc1=create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56f49cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   6 1196]]\n"
     ]
    }
   ],
   "source": [
    "rfc1=RandomForestClassifier(n_estimators=10,random_state=1,max_depth=7)\n",
    "rfc1=create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3611771b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>0.123524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>0.122089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>0.115948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>0.098439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>population</td>\n",
       "      <td>0.090818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.081767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>0.070126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>odor</td>\n",
       "      <td>0.058208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>0.052044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>0.046766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>habitat</td>\n",
       "      <td>0.036669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>0.023681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>0.023349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>0.014661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bruises</td>\n",
       "      <td>0.012393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>0.009648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>0.009425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.006562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>0.002196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>0.001687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input        IG\n",
       "0                  ring-type  0.123524\n",
       "1                 gill-color  0.122089\n",
       "2                  gill-size  0.115948\n",
       "3          spore-print-color  0.098439\n",
       "4                 population  0.090818\n",
       "5   stalk-surface-above-ring  0.081767\n",
       "6   stalk-surface-below-ring  0.070126\n",
       "7                       odor  0.058208\n",
       "8                 stalk-root  0.052044\n",
       "9     stalk-color-above-ring  0.046766\n",
       "10                   habitat  0.036669\n",
       "11              gill-spacing  0.023681\n",
       "12               stalk-shape  0.023349\n",
       "13    stalk-color-below-ring  0.014661\n",
       "14                   bruises  0.012393\n",
       "15                 cap-color  0.009648\n",
       "16               ring-number  0.009425\n",
       "17               cap-surface  0.006562\n",
       "18                 cap-shape  0.002196\n",
       "19                veil-color  0.001687\n",
       "20                 veil-type  0.000000\n",
       "21           gill-attachment  0.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':rfc1.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df4=pd.DataFrame(dict)\n",
    "df4.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a2bfbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min sample value :  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1234    2]\n",
      " [  31 1171]]\n",
      "min sample value :  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  30 1172]]\n",
      "min sample value :  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  30 1172]]\n",
      "min sample value :  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1228    8]\n",
      " [  31 1171]]\n",
      "min sample value :  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1229    7]\n",
      " [  31 1171]]\n",
      "min sample value :  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1227    9]\n",
      " [  31 1171]]\n",
      "min sample value :  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1227    9]\n",
      " [  31 1171]]\n",
      "min sample value :  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1226   10]\n",
      " [  31 1171]]\n",
      "min sample value :  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1227    9]\n",
      " [  31 1171]]\n",
      "min sample value :  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1227    9]\n",
      " [  31 1171]]\n",
      "min sample value :  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  31 1171]]\n",
      "min sample value :  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  31 1171]]\n",
      "min sample value :  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  31 1171]]\n",
      "min sample value :  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1229    7]\n",
      " [  31 1171]]\n",
      "min sample value :  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1233    3]\n",
      " [  31 1171]]\n",
      "min sample value :  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1233    3]\n",
      " [  31 1171]]\n",
      "min sample value :  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1222   14]\n",
      " [  31 1171]]\n",
      "min sample value :  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1222   14]\n",
      " [  31 1171]]\n",
      "min sample value :  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1222   14]\n",
      " [  31 1171]]\n",
      "min sample value :  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.99      0.98      0.98      2438\n",
      "weighted avg       0.99      0.98      0.98      2438\n",
      "\n",
      "[[1230    6]\n",
      " [  31 1171]]\n",
      "min sample value :  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1221   15]\n",
      " [  31 1171]]\n",
      "min sample value :  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1236\n",
      "           1       0.98      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1217   19]\n",
      " [  31 1171]]\n",
      "min sample value :  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1221   15]\n",
      " [  31 1171]]\n",
      "min sample value :  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1224   12]\n",
      " [  31 1171]]\n",
      "min sample value :  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  31 1171]]\n",
      "min sample value :  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  31 1171]]\n",
      "min sample value :  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  31 1171]]\n",
      "min sample value :  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  31 1171]]\n",
      "min sample value :  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  31 1171]]\n",
      "min sample value :  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  31 1171]]\n",
      "min sample value :  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  31 1171]]\n",
      "min sample value :  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  32 1170]]\n",
      "min sample value :  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  32 1170]]\n",
      "min sample value :  90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  32 1170]]\n",
      "min sample value :  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  32 1170]]\n",
      "min sample value :  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1225   11]\n",
      " [  31 1171]]\n",
      "min sample value :  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1225   11]\n",
      " [  37 1165]]\n",
      "min sample value :  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1236\n",
      "           1       0.99      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1221   15]\n",
      " [  37 1165]]\n",
      "min sample value :  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1236\n",
      "           1       0.99      0.96      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1221   15]\n",
      " [  43 1159]]\n",
      "min sample value :  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1236\n",
      "           1       0.99      0.96      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1221   15]\n",
      " [  43 1159]]\n",
      "min sample value :  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1236\n",
      "           1       0.99      0.96      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1222   14]\n",
      " [  50 1152]]\n",
      "min sample value :  98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1236\n",
      "           1       0.99      0.96      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1222   14]\n",
      " [  50 1152]]\n",
      "min sample value :  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1236\n",
      "           1       0.98      0.96      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1216   20]\n",
      " [  50 1152]]\n",
      "min sample value :  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1236\n",
      "           1       0.98      0.96      0.97      1202\n",
      "\n",
      "    accuracy                           0.97      2438\n",
      "   macro avg       0.97      0.97      0.97      2438\n",
      "weighted avg       0.97      0.97      0.97      2438\n",
      "\n",
      "[[1216   20]\n",
      " [  52 1150]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(45,101,1):\n",
    "    rfc2=RandomForestClassifier(n_estimators=10,random_state=1,min_samples_leaf=i) #bydefault gini\n",
    "    print(\"min sample value : \",i)\n",
    "    #call function \n",
    "    rfc2=create_model(rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c2b94bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1234    2]\n",
      " [  31 1171]]\n"
     ]
    }
   ],
   "source": [
    "rfc2=RandomForestClassifier(n_estimators=10,random_state=1,min_samples_leaf=45)\n",
    "rfc2=create_model(rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb9890a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>0.139738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>0.116574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>0.109627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>population</td>\n",
       "      <td>0.099885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>0.096794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.090016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>odor</td>\n",
       "      <td>0.077774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bruises</td>\n",
       "      <td>0.050436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>0.050334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>0.046276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>0.024388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>0.022863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>0.021822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.017087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>0.011868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>0.009088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>0.006987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>0.004334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>habitat</td>\n",
       "      <td>0.003319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input        IG\n",
       "0                 gill-color  0.139738\n",
       "1                  gill-size  0.116574\n",
       "2                  ring-type  0.109627\n",
       "3                 population  0.099885\n",
       "4          spore-print-color  0.096794\n",
       "5   stalk-surface-above-ring  0.090016\n",
       "6                       odor  0.077774\n",
       "7                    bruises  0.050436\n",
       "8                 stalk-root  0.050334\n",
       "9     stalk-color-above-ring  0.046276\n",
       "10  stalk-surface-below-ring  0.024388\n",
       "11    stalk-color-below-ring  0.022863\n",
       "12              gill-spacing  0.021822\n",
       "13               cap-surface  0.017087\n",
       "14               stalk-shape  0.011868\n",
       "15                 cap-color  0.009088\n",
       "16               ring-number  0.006987\n",
       "17                 cap-shape  0.004334\n",
       "18                   habitat  0.003319\n",
       "19           gill-attachment  0.000790\n",
       "20                veil-color  0.000000\n",
       "21                 veil-type  0.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':rfc2.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df5=pd.DataFrame(dict)\n",
    "df5.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8e2a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply ensembling technique boosting\n",
    "#1. first apply ADA boost: call inbuilt class AdaBoostClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d1eca324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 22)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "161214aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Decision stump:  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81      1236\n",
      "           1       0.84      0.71      0.77      1202\n",
      "\n",
      "    accuracy                           0.79      2438\n",
      "   macro avg       0.80      0.79      0.79      2438\n",
      "weighted avg       0.80      0.79      0.79      2438\n",
      "\n",
      "[[1071  165]\n",
      " [ 349  853]]\n",
      "No. of Decision stump:  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83      1236\n",
      "           1       0.80      0.90      0.85      1202\n",
      "\n",
      "    accuracy                           0.84      2438\n",
      "   macro avg       0.85      0.84      0.84      2438\n",
      "weighted avg       0.85      0.84      0.84      2438\n",
      "\n",
      "[[ 968  268]\n",
      " [ 116 1086]]\n",
      "No. of Decision stump:  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      1236\n",
      "           1       0.97      0.76      0.85      1202\n",
      "\n",
      "    accuracy                           0.87      2438\n",
      "   macro avg       0.89      0.87      0.87      2438\n",
      "weighted avg       0.89      0.87      0.87      2438\n",
      "\n",
      "[[1211   25]\n",
      " [ 288  914]]\n",
      "No. of Decision stump:  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1236\n",
      "           1       0.96      0.92      0.94      1202\n",
      "\n",
      "    accuracy                           0.94      2438\n",
      "   macro avg       0.94      0.94      0.94      2438\n",
      "weighted avg       0.94      0.94      0.94      2438\n",
      "\n",
      "[[1188   48]\n",
      " [ 101 1101]]\n",
      "No. of Decision stump:  5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1236\n",
      "           1       0.93      0.92      0.93      1202\n",
      "\n",
      "    accuracy                           0.93      2438\n",
      "   macro avg       0.93      0.93      0.93      2438\n",
      "weighted avg       0.93      0.93      0.93      2438\n",
      "\n",
      "[[1154   82]\n",
      " [  93 1109]]\n",
      "No. of Decision stump:  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      1236\n",
      "           1       0.97      0.92      0.94      1202\n",
      "\n",
      "    accuracy                           0.95      2438\n",
      "   macro avg       0.95      0.95      0.95      2438\n",
      "weighted avg       0.95      0.95      0.95      2438\n",
      "\n",
      "[[1204   32]\n",
      " [ 101 1101]]\n",
      "No. of Decision stump:  7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1236\n",
      "           1       1.00      0.92      0.96      1202\n",
      "\n",
      "    accuracy                           0.96      2438\n",
      "   macro avg       0.96      0.96      0.96      2438\n",
      "weighted avg       0.96      0.96      0.96      2438\n",
      "\n",
      "[[1234    2]\n",
      " [ 101 1101]]\n",
      "No. of Decision stump:  8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1236\n",
      "           1       1.00      0.95      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1234    2]\n",
      " [  55 1147]]\n",
      "No. of Decision stump:  9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1236\n",
      "           1       1.00      0.96      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  45 1157]]\n",
      "No. of Decision stump:  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1236\n",
      "           1       1.00      0.96      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  45 1157]]\n",
      "No. of Decision stump:  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  32 1170]]\n",
      "No. of Decision stump:  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1236\n",
      "           1       1.00      0.99      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1232    4]\n",
      " [  13 1189]]\n",
      "No. of Decision stump:  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1233    3]\n",
      " [   5 1197]]\n",
      "No. of Decision stump:  14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1233    3]\n",
      " [   5 1197]]\n",
      "No. of Decision stump:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1233    3]\n",
      " [   5 1197]]\n",
      "No. of Decision stump:  16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1233    3]\n",
      " [   5 1197]]\n",
      "No. of Decision stump:  17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1233    3]\n",
      " [   5 1197]]\n",
      "No. of Decision stump:  18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n",
      "No. of Decision stump:  19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n",
      "No. of Decision stump:  20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No. of Decision stump:  21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n",
      "No. of Decision stump:  22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,23):\n",
    "    ada=AdaBoostClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Decision stump: \",i)\n",
    "    #call function\n",
    "    ada=create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ae4c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1233    3]\n",
      " [   5 1197]]\n"
     ]
    }
   ],
   "source": [
    "#create the object of AdaBoostClassifier class\n",
    "#ADA Boost creates decision stump (means one root node and 2 leaf node)\n",
    "#leaf node: no any childs\n",
    "ada=AdaBoostClassifier(n_estimators=13,random_state=1)\n",
    "#n_estimators means how many decision stumps, decision stumps depend on \n",
    "#no. of input\n",
    "#in case of our dataset, no. of features means inputs=13\n",
    "#call function\n",
    "ada=create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f16b14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>odor</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>habitat</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>population</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bruises</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input        IG\n",
       "0                       odor  0.384615\n",
       "1          spore-print-color  0.307692\n",
       "2                 gill-color  0.153846\n",
       "3                    habitat  0.076923\n",
       "4   stalk-surface-below-ring  0.076923\n",
       "5                 population  0.000000\n",
       "6                  ring-type  0.000000\n",
       "7                ring-number  0.000000\n",
       "8                 veil-color  0.000000\n",
       "9                  veil-type  0.000000\n",
       "10    stalk-color-below-ring  0.000000\n",
       "11    stalk-color-above-ring  0.000000\n",
       "12                 cap-shape  0.000000\n",
       "13               cap-surface  0.000000\n",
       "14                stalk-root  0.000000\n",
       "15               stalk-shape  0.000000\n",
       "16                 gill-size  0.000000\n",
       "17              gill-spacing  0.000000\n",
       "18           gill-attachment  0.000000\n",
       "19                   bruises  0.000000\n",
       "20                 cap-color  0.000000\n",
       "21  stalk-surface-above-ring  0.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':ada.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df=pd.DataFrame(dict)\n",
    "df.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e4ca290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call inbuilt class for Gradient Boosting: GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "163439ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of estimators:  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1236\n",
      "           1       1.00      0.96      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1234    2]\n",
      " [  47 1155]]\n",
      "No of estimators:  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1234    2]\n",
      " [  37 1165]]\n",
      "No of estimators:  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1234    2]\n",
      " [  37 1165]]\n",
      "No of estimators:  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1234    2]\n",
      " [  37 1165]]\n",
      "No of estimators:  14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1234    2]\n",
      " [  37 1165]]\n",
      "No of estimators:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1234    2]\n",
      " [  37 1165]]\n",
      "No of estimators:  16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.98      0.98      0.98      2438\n",
      "weighted avg       0.98      0.98      0.98      2438\n",
      "\n",
      "[[1234    2]\n",
      " [  37 1165]]\n",
      "No of estimators:  17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.99      0.98      0.98      2438\n",
      "weighted avg       0.99      0.98      0.98      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  37 1165]]\n",
      "No of estimators:  18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.99      0.98      0.98      2438\n",
      "weighted avg       0.99      0.98      0.98      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  37 1165]]\n",
      "No of estimators:  19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1236\n",
      "           1       1.00      0.97      0.98      1202\n",
      "\n",
      "    accuracy                           0.98      2438\n",
      "   macro avg       0.99      0.98      0.98      2438\n",
      "weighted avg       0.99      0.98      0.98      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  37 1165]]\n",
      "No of estimators:  20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  30 1172]]\n",
      "No of estimators:  21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  30 1172]]\n",
      "No of estimators:  22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  27 1175]]\n",
      "No of estimators:  23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  27 1175]]\n",
      "No of estimators:  24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  27 1175]]\n",
      "No of estimators:  25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  27 1175]]\n",
      "No of estimators:  26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  27 1175]]\n",
      "No of estimators:  27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  27 1175]]\n",
      "No of estimators:  28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  27 1175]]\n",
      "No of estimators:  29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  27 1175]]\n",
      "No of estimators:  30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  27 1175]]\n",
      "No of estimators:  31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  20 1182]]\n",
      "No of estimators:  32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  20 1182]]\n",
      "No of estimators:  33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  20 1182]]\n",
      "No of estimators:  34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  20 1182]]\n",
      "No of estimators:  35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  20 1182]]\n",
      "No of estimators:  36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  20 1182]]\n",
      "No of estimators:  37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1236\n",
      "           1       1.00      0.98      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  20 1182]]\n",
      "No of estimators:  38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1236\n",
      "           1       1.00      0.99      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  15 1187]]\n",
      "No of estimators:  39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n",
      "No of estimators:  40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1236\n",
      "           1       1.00      0.99      0.99      1202\n",
      "\n",
      "    accuracy                           0.99      2438\n",
      "   macro avg       0.99      0.99      0.99      2438\n",
      "weighted avg       0.99      0.99      0.99      2438\n",
      "\n",
      "[[1236    0]\n",
      " [  15 1187]]\n",
      "No of estimators:  41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n",
      "No of estimators:  42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n",
      "No of estimators:  43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n",
      "No of estimators:  44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n",
      "No of estimators:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n",
      "No of estimators:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n",
      "No of estimators:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   2 1200]]\n",
      "No of estimators:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   2 1200]]\n",
      "No of estimators:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "#Create the object of GradientBoostingClassifier class  and passing the \n",
    "#parameter n_estimators means how many iteration means how many\n",
    "#decisionTree use for train the model\n",
    "\n",
    "for i in range(10,101,1):\n",
    "    gbc=GradientBoostingClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No of estimators: \",i)\n",
    "    #call function\n",
    "    gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6821999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   5 1197]]\n"
     ]
    }
   ],
   "source": [
    "#Create the object of GradientBoostingClassifier class\n",
    "gbc=GradientBoostingClassifier(n_estimators=41,random_state=1)\n",
    "gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70637511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>odor</td>\n",
       "      <td>3.318923e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>2.657907e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>1.600834e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>population</td>\n",
       "      <td>1.356305e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>5.167614e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>2.529484e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>7.888395e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>7.168613e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>5.515623e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>5.270476e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>habitat</td>\n",
       "      <td>1.381459e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>1.357464e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>7.169599e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>1.911893e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>1.049537e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>2.704373e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bruises</td>\n",
       "      <td>1.002495e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>4.191572e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input            IG\n",
       "0                       odor  3.318923e-01\n",
       "1                 gill-color  2.657907e-01\n",
       "2          spore-print-color  1.600834e-01\n",
       "3                 population  1.356305e-01\n",
       "4                  gill-size  5.167614e-02\n",
       "5                 stalk-root  2.529484e-02\n",
       "6     stalk-color-below-ring  7.888395e-03\n",
       "7     stalk-color-above-ring  7.168613e-03\n",
       "8                ring-number  5.515623e-03\n",
       "9   stalk-surface-below-ring  5.270476e-03\n",
       "10                   habitat  1.381459e-03\n",
       "11               stalk-shape  1.357464e-03\n",
       "12              gill-spacing  7.169599e-04\n",
       "13                 cap-color  1.911893e-04\n",
       "14                veil-color  1.049537e-04\n",
       "15                 ring-type  2.704373e-05\n",
       "16                   bruises  1.002495e-05\n",
       "17                 cap-shape  4.191572e-18\n",
       "18                 veil-type  0.000000e+00\n",
       "19               cap-surface  0.000000e+00\n",
       "20           gill-attachment  0.000000e+00\n",
       "21  stalk-surface-above-ring  0.000000e+00"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':gbc.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df=pd.DataFrame(dict)\n",
    "df.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "406cedb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\shra\\anaconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\shra\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\shra\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb029eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call inbuilt class:XGBClassifier which definbe in package xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bdc5eac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of estimators:  10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n",
      "No of estimators:  100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,101,1):\n",
    "    xgc=XGBClassifier(n_estimators=i,reg_alpha=1,random_state=1)\n",
    "    print(\"No of estimators: \",i)\n",
    "    #call function\n",
    "    xgc=create_model(xgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ba897fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "#create object of XGBClassifier class\n",
    "xgc=XGBClassifier(n_estimators=10,reg_alpha=1,random_state=1)\n",
    "#reg means regularisation\n",
    "#alpha means lambda means hyper parameter\n",
    "#if reg_alpha=1, 1 means True means automatic handle outlier and overfitting\n",
    "#call function\n",
    "xgc=create_model(xgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77c7f44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gill-color</td>\n",
       "      <td>0.413558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>population</td>\n",
       "      <td>0.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spore-print-color</td>\n",
       "      <td>0.102109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gill-size</td>\n",
       "      <td>0.098053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>odor</td>\n",
       "      <td>0.036104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stalk-shape</td>\n",
       "      <td>0.034176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bruises</td>\n",
       "      <td>0.033413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stalk-color-above-ring</td>\n",
       "      <td>0.024860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>habitat</td>\n",
       "      <td>0.019352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stalk-root</td>\n",
       "      <td>0.011596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stalk-color-below-ring</td>\n",
       "      <td>0.010212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cap-color</td>\n",
       "      <td>0.007692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cap-surface</td>\n",
       "      <td>0.006491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stalk-surface-below-ring</td>\n",
       "      <td>0.005278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ring-type</td>\n",
       "      <td>0.005097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ring-number</td>\n",
       "      <td>0.002509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cap-shape</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>veil-color</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>veil-type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gill-spacing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gill-attachment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stalk-surface-above-ring</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       input        IG\n",
       "0                 gill-color  0.413558\n",
       "1                 population  0.189500\n",
       "2          spore-print-color  0.102109\n",
       "3                  gill-size  0.098053\n",
       "4                       odor  0.036104\n",
       "5                stalk-shape  0.034176\n",
       "6                    bruises  0.033413\n",
       "7     stalk-color-above-ring  0.024860\n",
       "8                    habitat  0.019352\n",
       "9                 stalk-root  0.011596\n",
       "10    stalk-color-below-ring  0.010212\n",
       "11                 cap-color  0.007692\n",
       "12               cap-surface  0.006491\n",
       "13  stalk-surface-below-ring  0.005278\n",
       "14                 ring-type  0.005097\n",
       "15               ring-number  0.002509\n",
       "16                 cap-shape  0.000000\n",
       "17                veil-color  0.000000\n",
       "18                 veil-type  0.000000\n",
       "19              gill-spacing  0.000000\n",
       "20           gill-attachment  0.000000\n",
       "21  stalk-surface-above-ring  0.000000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'input':x.columns,'IG':xgc.feature_importances_}\n",
    "#convert dict into dataframe\n",
    "df2=pd.DataFrame(dict)\n",
    "df2.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc5c0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give data in support vector machine\n",
    "#1. Linear kernal function of svm: \n",
    "#means suppose data are linear separatable with the help of straight line\n",
    "#call inbuilt class for linear svm: LinearSVC\n",
    "#SVC means support vector classifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8dcd945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of LinearSVC class\n",
    "svc=LinearSVC(random_state=1)  #no add nay error means suppose no outlier\n",
    "#in iur dataset means it is hard margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abf35d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1236\n",
      "           1       0.96      0.94      0.95      1202\n",
      "\n",
      "    accuracy                           0.95      2438\n",
      "   macro avg       0.95      0.95      0.95      2438\n",
      "weighted avg       0.95      0.95      0.95      2438\n",
      "\n",
      "[[1188   48]\n",
      " [  69 1133]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "svc=create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0042e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply KNN algorithm: inbuilt class KNeighborsClassifier which define in \n",
    "#outer class neighbors and outer class define in package sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3febc189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of KNeighborsClassifier class and passing some parameters\n",
    "knc=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "#p=2 means Euclidean distance method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6dd7693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1236\n",
      "           1       1.00      1.00      1.00      1202\n",
      "\n",
      "    accuracy                           1.00      2438\n",
      "   macro avg       1.00      1.00      1.00      2438\n",
      "weighted avg       1.00      1.00      1.00      2438\n",
      "\n",
      "[[1236    0]\n",
      " [   0 1202]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "knc=create_model(knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "746e2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this model, RandomForest, DecisionTree and KNN have the best accuracy with 100%,\n",
    "#but SVC and Logistic Regression is not the best performance. So, better to use RandomForestClassifier \n",
    "#or DecisionTreeClassifier or KNN to classify any new Mushroom class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f1123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
